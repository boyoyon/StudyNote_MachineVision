<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>はじめに</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
            .margin-large
            {
                margin-left: 30px;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .two-columns {
            display: flex;
            flex-direction: row;
            gap: 20px; /* 列間のスペース */
        }
        .column {
            flex: 1; /* 各列が均等に幅を取る */
        }
    </style>
<style>
.three-columns {
  display: flex;
  gap: 10px; /* 列間の余白を設定 */
}
.column {
  flex: 1; /* 各列の幅を均等にする */
  padding: 10px; /* 内側の余白を設定 */
}
</style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -30px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 50px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
            ol
            {
                margin-left: 30px;
            }
            ul
            {
                margin-left: 30px;
            }
    </style>
    </head>
    <body>
        <h1><center>1章  はじめに</center></h1>
<h2>1.1  マシンビジョン</h2>
<p>
マシンビジョンシステムの目標は、画像から現実の世界のモデルを作る事である。マシンビジョンシステムは2次元の投影から場面に関する有益な情報を復元する。画像は3次元世界の投影なので、情報は直接には手に入らず復元しなければならない。この復元は多対1の写像の反転を必要とする。情報を復元するために場面内のオブジェクトに関する知識や投影幾何学が必要になる。
</p>
<p>
  マシンビジョンシステムの応用と必要とされる処理の種類を考えるため、図1.1から1.3に示す3つの画像を考えよう。これらの図はマシンビジョンシステムの3つの異なる応用例を示している。3つの例ではビジョンシステムによって復元される情報が異なる。最初の図ではコンピュータトモグラフィー画像を使って病気の診断をすることが関心事である。マシンビジョンは画像を強調することで医者が情報を復元するのを助ける。注目領域を量的に測定することで情報の入手を簡単にする事も出来る。この様なシステムは健康管理の様々な局面で役に立つあらゆる画像処理様式用に開発されてきた。同様の応用は、工業、農業､他の製品検査用としても開発されてきた。マシンビジョンシステムはピザからタービンの羽根、ウェファーのサブミクロン構造から自動車ボディーパネル、りんごからオレンジの広がりを持つ製品の品質管理にも使われている。
</p>
<center><img src="images/fig1_1.png"></center><br>
<p>
図1.1  診断の支援として医療用画像がコンピュータビジョンシステムで処理される事もある。この画像は軟部組織ウィンドウ設定での人の肝臓のコントラスト強調CT(X線コンピュータトモグラフィー断面)画像である。
</p>
<p>
  図1.2は移動型ロボットで撮影した2枚の画像対である。各画像対はある時刻におけるステレオ画像対である。これらの画像はロボットが環境内を自律的にナビゲーションする事を目的として、環境の3次元構造を復元するために使われる。ステレオ画像や動きから得られる情報は、作業を行うのに十分な解像度のしっかりした環境地図を得るために組み合わせられる。この様な技術は自動車や飛行機、戦車、ロボットの自律的なナビゲーションで役に立つ。画像内の点の奥行きを復元する方法には何通りもある事を後で見る事にする。通常、信頼できる奥行き値を復元するためには、それらの幾つかを組み合わせなければならない。
</p>
<center><img src="images/fig1_2.png"></center><br>
<p>
図1.2  移動型ロボットで撮影した2組のステレオ画像対。これらはロボットによる環境レイアウトの復元に使われる。
</p>
<center><img src="images/fig1_3.png"></center><br>
<p>
図1.3  北極圏の画像。この画像は流氷やその他の物体の年代や大きさを求めるために解析される。
</p>
<h2>1.2  他の分野との関連</h2>
<p>
多くの分野がマシンビジョンと関連している。これから見ていく様に、多くの領域で開発された技術が画像から情報を復元するために使われる。この節では密接に関連したいくつかの分野について簡単に述べる。マシンビジョン(コンピュータビジョンとも呼ばれる)と他の分野を関連付けるのに何の努力も要らない。
</p>
<p>
  画像処理は十分に開発された分野である。画像処理技術は通常、画像を別の画像に変換する。情報復元の作業は人間であるユーザーに残されている。この分野では画像強調、画像圧縮、ブレやピンボケ画像の補正と言ったトピックが含まれる。これに対してマシンビジョンアルゴリズムは、入力として画像を受け取り、画像内のオブジェクト(被写体)輪郭の表現といった別のタイプの出力を生成する。従ってマシンビジョンにおける重点は、人間との最小限の対話で情報を自動的に復元する事に置かれる。画像処理アルゴリズムはマシンビジョンシステムの初期工程で役に立つ。それらは通常、特定の情報を強調しノイズを抑圧するために使われる。
</p>
<p>
  コンピュータグラフィックスは直線、円、自由曲面と言った幾何学プリミティブから画像を生成する。コンピュータグラフィックス技術は視覚化、仮想現実で重要な役割を演じる。マシンビジョンは逆問題である。画像から幾何学やその他の特徴を推定する。つまりコンピュータグラフィックスは画像の生成であり、マシンビジョンは画像の解析である。これら2つの分野の初期には、あまり関連が無かった。しかしここ数年、2つの分野は接近しつつある。マシンビジョンはコンピュータグラフィックスから曲線、曲面表現、その他の技術を借り、コンピュータグラフィックスは写実的な画像を作るためにコンピュータにモデルを入力する方法としてマシンビジョンから多くの技術を借りている。視覚化と仮想現実がこの2つの分野を近づけている。
</p>
<p>
  パターン認識は数字や記号データを分類する。多くの統計技術、構文技術がパターンの分類用に開発されてきた。パターン認識からの技術はマシンビジョンでオブジェクトを認識する際に重要な役割を果たす。実際、多くの工業的な応用はパターン認識に大きく依存している。マシンビジョンにおけるオブジェクト認識は通常、他の多くの技術を必要とする。オブジェクト認識について述べる際に、統計的パターン認識の局面の幾つかを簡単に述べる。
</p>
<p>
  人工知能は知的なシステムを設計する事と、知性のコンピュータ処理的な局面を研究する事に関係している。人工知能は、画像が処理され特徴が取り出された後で、場面内容の記号的表現を計算する事によって解析するために使われる。人工知能は3段階を持っていると見なす事が出来るかもしれない。知覚、認知、行動である。知覚は世界から記号へ信号を翻訳し、認知は記号を操作し、行動は世界を変化させる信号に記号を翻訳する。人工知能からの技術の多くがコンピュータビジョンの全ての局面で重要な役割を果たす。実際、コンピュータビジョンは人工知能の一分野と見なされる事が多い。
</p>
<p>
  ニューラルネットワークの設計と解析はここ10年間で非常に活発な分野になった。ニューラルネットワークはマシンビジョンのいくつかの問題の解決に適用されるようになってきている。この分野はまだ揺籃期なので、マシンビジョンに対してはまだ確立された技術が無い。本書ではニューラルネットワークベースの技術については述べない。
</p>
<p>
  認知科学と共に精神物理学は長い間、人間の視覚を研究してきた。マシンビジョンの多くの技術は人間の視覚について分かっている事と関連している。コンピュータビジョン研究者の多くはマシンビジョンシステムを設計することよりも、人間の視覚のコンピュータ処理モデルを作成する事に関心を持っている。本書で述べる技術の多くは精神物理学の技術とかなり類似している。本書での我々の重点はマシンビジョンを設計する事に置かれている。我々はここで述べる技術を精神物理学の技術と関連付ける事はしない。
</p>
<p>
  マシンビジョンは幾何学的特性から計量や抽象物を生成する。以下の式を覚えておくと便利かもしれない。
\[
視覚＝幾何学+計量+解釈 \tag{1.1}
\]
</p>
<p>
本書でこれから見る様にマシンビジョンは、空間内のオブジェクトの幾何学の特徴計量と関連した画像内の特徴を推定し、この幾何学情報を解釈する技術から成っている。
</p>
<h2>1.3  知識の役割</h2>
<p>
判断は常にアプリケーションや目標についての知識を必要とする。これから見るように、マシンビジョンの各工程で判断はシステムが行う。マシンビジョンシステムの重点は、各工程の自動動作を最大化する事に置かれており、これを実現するためにシステムは知識を使うべきである。システムが使う知識にはモデルの特徴、画像情報、オブジェクトのモデル、オブジェクト間の関係が含まれる。知識を明示的に使用しないとマシンビジョンシステムは非常に限定された環境で非常に限られたアプリケーションにしか適用できない。柔軟性と堅牢さを提供するためには、知識を明示的に表現しシステムはそれを使う。本書での我々の目標は、システムをより適応的に堅牢にするために考慮すべき問題を読者に気づいてもらうために、マシンビジョンシステムのそれぞれの工程で使われる知識の種類を指摘する事である。システム設計者により知識が明示的な形だけでなく非明示的な形でも使われる事を見るであろう。システムの効力と効率は一般的にシステムで使われる知識の質に支配される。困難な問題は適正な知識源を知り、システム内で知識を使う適当なメカニズムを知る事によってのみ解決される事が多い。
</p>
<h2>1.4  画像幾何学</h2>
<p>
画像の形成工程には2つの部分がある。
<div class="styleBullet">
<ul>
<li>1. 画像形成の幾何学－場面内の点の投影が画像平面のどこに位置するかを決める</li>
<li>2. 照明の物理学－場面の照明と表面属性の関数として画像内の点の輝度を決める</li>
</ul>
</div>
<p>
この節では、これら2つの部分の内の1番目、画像形成の幾何学を紹介する。たいていの視覚アルゴリズムを理解するためには、照明の物理学を理解する必要はないが、その様な知識はビジョンシステムを構築する上で役に立つ事が多い。このため8章で簡単に光学にふれ、輻射測定(radiometry)と呼ばれる画像形成の物理学を9章で述べる。
</p>
<center><img src="images/fig1_4.png"></center><br>
<p>
図1.4　場面内の特定の点と対応する画像平面上の点は、場面上の点と投影中心を通る直線を辿ることで見つけられる。
</p>
<p>
  場面内の点の画像平面への投影の基本モデルを図1.4に図示する。このモデルでは画像処理システムの投影中心と3次元座標系の原点が一致している。場面内の点に対する座標系は、座標軸を形成する単位ベクトル \(x,y,z\) が張る3次元空間である。場面内の点は座標\((x,y,z)\)を持つ。\(x\) 座標はカメラから見た空間内の点の水平位置であり、\(y\) 座標はカメラから見た空間内の点の垂直位置、\(z\) 座標は空間内の点からカメラまでの距離を \(z\) 軸と平行な直線に沿って測った値である。空間内の点の視線とは、注目点と投影中心を通る直線の事である。図1.4に描かれている直線は視線である。
</p>
<p>
  図1.4に示す様に画像平面は座標系の \(x\) 軸、\(y\) 軸と平行で、投影中心から距離 \(f\) にある。実際のカメラの画像平面は投影中心の後ろ側の距離 \(f\) にあり(図1.4に示したとおり)、投影された画像は反転している。図1.5に示す様に、画像平面が投影中心の前にあると仮定する事により、反転を避ける事が慣例になっている。画像平面はベクトル \(x',y'\) で張られ、画像平面内の点を指定する2次元座標系を形成する。画像平面内の点の位置は2つの座標 \(x'\) と \(y'\) で指定される。画像平面内の点 \((0,0)\) は画像平面の原点である。場面内の点の画像平面での位置は、続く節で述べる投影手法に従って画像平面と視線を交わらせる事で見つけられる。
</p>
<center><img src="images/fig1_5.png"></center><br>
<p>
図1.5　注目点 \((x, y, z)\) から投影された点 \((x', y')\) を計算するために使われる視線を示した図
</p>
<h3>1.4.1  透視投影</h3>
<p>
場面内の位置 \((x,y,z)\) の点の画像平面での位置 \((x',y')\) は、図1.5に示す様に場面点 \((x,y,z)\) と画像平面を通る視線の交点座標 \((x',y')\) を計算する事で見つけられる。
</p>
<p>
　点 \((x,y,z)\) の \(z\) 軸からの距離は \(r=\sqrt{x^2+y^2}\) で、投影点 \((x',y')\) と画像平面の原点との距離は \(r'=\sqrt{x'^2+y'^2}\) である。\(z\) 軸、点 \((x,y,z)\) への視線、点 \((x,y,z)\) から \(z\) 軸への長さ \(r\) の線分(\(z\) 軸への垂線)は三角形を作る。\(z\) 軸、画像平面内の点 \((x',y')\) への視線、点 \((x',y')\) から \(z\) 軸への長さ \(r'\) の線分(\(z\) 軸への垂線)も三角形を作る。2つの三角形は相似なので、三角形の対応する辺の比は同じである。
\[
\frac{f}{z}=\frac{r'}{r} \tag{1.2}
\]
\(x\) 座標、\(y\) 座標と長さ \(r\) の垂線が作る三角形と、画像平面座標 \(x',y'\) と長さ \(r'\) の垂線が作る三角形も相似である。
\[
\frac{x'}{x}=\frac{y'}{y}=\frac{r'}{r} \tag{1.3}
\]
式1.2と1.3を組み合わせると透視投影の式が出来る。
\[
\frac{x'}{x}=\frac{f}{z}　と　\frac{y'}{y}=\frac{f}{z} \tag{1.4}
\]
点 \((x,y,z)\) に対応する画像平面内の位置は次式で与えられる。
\[
\begin{align}
x' &=\frac{f}{z}x \tag{1.5} \\
\\
y' &=\frac{f}{z}y \tag{1.6}
\end{align}
\]
</p>
<h3>1.4.2  座標系</h3>
<p>
ここでの説明では、投影中心が3次元空間の原点と一致し、カメラ軸が空間内で点の位置を指定するための座標系と整列していると仮定している。一般には、カメラは場面内で座標を指定するために使われる座標系とは、ずれや回転が存在する。絶対座標系の座標\((x_a,y_a,z_a)\) は、点を画像平面に投影する前にカメラ座標系での座標 \((x_c,y_c,z_c)\) に変換しなければならない。一般の場合が12章、校正で説明される。そこでは座標系間の座標変換の数学も含んでいる。絶対座標はワールド座標とも呼ばれる。
  個々のオブジェクトはモデル座標と呼ばれる、自身の座標系を持つ場合がある。場面は、場面内に(回転したり、平行移動したりして)置かれたオブジェクトモデルからなっており、場面の座標系(絶対座標)の中のオブジェクト座標を生じる。絶対座標系での場面の座標は画像平面に投影する前に、カメラ座標に変換する。
</p>
<p>
　本書全体を通して、座標系を表すために添え字を使い、画像平面上に投影された後の画像平面座標系を表記するためにプライム記号(')を使う。座標系が明らかな場合は添え字を省き、座標が画像平面内である事が明らかな場合にはプライム記号を省く。これらのルールにより必要な時には座標系を明確にしたり、カメラ座標の点と画像平面上への投影とを区別したりする事ができ、しかも曲面や曲線の式を説明する際には解析幾何で点の座標を共通使用するために表記を簡単化する事が出来る。
</p>
<p>
　このルールに従うと、本章のこの後と、画像平面に制限されたマシンビジョンアルゴリズムを扱う2章から6章にかけては、画像平面座標からプライム記号を省略できる。
</p>
<h2>1.5  標本化と量子化</h2>
<p>
連続関数はディジタルコンピュータで正確に表現できない。画像平面上に場面を投影する光学系とコンピュータの間のインターフェイスは、有限の数の点に画像を標本化し、各サンプルをコンピュータの有限ワード長で表現しなければならない。これが標本化と量子化である。画像の各サンプルはピクセルと呼ばれる。我々は先ず、画像が全体にわたって水平、垂直に等間隔で規則的な矩形格子に標本化されると仮定する。我々はこの仮定を12章で一般化する。各ピクセルはコンピュータ内では小さな整数値で表現される。ピクセルは \(0\) から \(255\) の範囲となる符号無し8ビット整数で表現される事が多い。ここで \(0\) は黒に対応し、\(255\) は白、中間階調にはそれらの間の値が割り当てられる。
</p>
<p>
　多くのカメラはアナログ画像を取り込み、その後で標本化、量子化されてディジタル画像に変換される。サンプリングレートはディジタル画像がどれくらい多くのピクセルを持つか(画像解像度)を決め、量子化は各サンプル点の輝度を表現するためにどれくらい多くの輝度値を使うかを決める。図1.6、1.7に示す様に、異なるサンプリングレート、量子化レベルでは画像は非常に異なって見える。たいていのマシンビジョンアプリケーションでは、カメラや画像取り込みハードウェアの選択肢が限られているため標本化や量子化レートは予め決められている。しかし多くの応用で標本化と量子化の影響を知っておく事が重要になるかもしれない。画像処理の文献では、画像内の重要な情報を失わない様に適当なサンプリングレートと量子化レートを選択する際に考慮すべき要因について述べられている。
</p>
<center><img src="images/fig1_6.png"></center>
<p>
<center>図1.6  異なる空間解像度の画像を示す</center>
</p>
<center><img src="images/fig1_7.png"></center>
<p>
<center>図1.7  異なる階調数の画像</center>
</p>
<h2>1.6  画像定義</h2>
<p>
前の節で述べた画像形成の幾何学と、コンピュータ内部での画像表現の間の関係を理解しておく事は重要である。マシンビジョンアルゴリズムを開発するために使われる表記法からプログラムの中で使われるアルゴリズム表記に橋渡しするものが必要である。
</p>
<p>
  ピクセルは整数値に量子化された輝度画像のサンプルである。画像はピクセルの2次元配列である。ピクセルの行、列のインデックス \([i,j]\) は、ピクセル値の配列の行と列を指定する整数値である。ピクセル \([0,0]\) は画像の左上にある。インデックス \(i\) は右を指し、\(j\) は下を指す。このインデックス表記はコンピュータプログラムで使われる配列構文と密接に対応する。画像平面内の点の位置は \(x,y\) 座標を持つ。\(y\) 座標は垂直方向に対応し、\(x\) 座標は水平方向に対応する。\(y\) 軸は上を指し、\(x\) 軸は右を指す。ピクセルインデックス \([i,j]\) の2つのインデックス \(i,j\) に対応する方向は、位置 \((x,y)\) のそれぞれの座標に対応する方向とは反転している事に注意して欲しい。
</p>
<p>
  \(x\) 座標、\(y\) 座標は実数であり、コンピュータでは浮動小数点として格納される。画像平面座標 \((x,y)\) は \(m×n\) ピクセル配列のピクセル座標 \([i,j]\) から以下の式を使って計算できる。
\[
\begin{align}
x &=j-\frac{m-1}{2} \tag{1.7} \\
y &=-\left(i-\frac{n-1}{2}\right) \tag{1.8}
\end{align}
\]
ここで画像平面座標系の原点は画像配列の中心と対応していると仮定している。
</p>
<p>
  画像処理システムでは、各ピクセルは画像平面上のある有限領域を占めている。ピクセルの厳密な形状に依存する様なマシンビジョンアルゴリズムは本書では扱わないので、画像平面のピクセル分割は等しいサイズの正方形であると具体的に仮定しても良いであろう。画像平面内の位置はピクセルの一部として表現される。インデックス \([i,j]\) を持つピクセルの座標 \((x_{ij},y_{ij})\) は画像平面座標系におけるピクセルの中心に位置している。我々は画像平面内のピクセルの中心位置(画像サンプルはそこで取られる)にしか興味が無いので、ピクセルは更に画像平面内の1点へと抽象化する事も出来る。コンピュータプログラム内のピクセルの配列は図1.8に示すように、サンプルが取られる位置の画像平面内の格子に対応する。
</p>
<center><img src="images/fig1_8.png"></center>
<p>
図1.8　画像平面座標と画像配列インデックスの関係。\(x-y\) 平面の原点の位置は画像配列に対して任意であることに注意
</p>
<p>
  図示した様に画像を、ピクセルの画像輝度で陰影付けされている各矩形領域のモザイクとして示す事が出来る。これは純粋に視覚化の手法であり、ピクセルの形が記述するアルゴリズムにとって重要だと言う事を意味するものではない。本書で述べるほとんどすべてのアルゴリズムの目的のため、画像輝度をサンプルした正方格子として画像をモデル化する事が出来る。カメラやディジタイズ機器はこの仮定を満足させる様に設計されている。行と列で間隔が異なるとか、レンズの不完全さによる歪みやカメラの取り付け誤差の様な変動の幾つかは、画像処理アルゴリズムを変更しなくても校正により取り除く事が出来る(12.9節参照)。
</p>
<p>
  要約すると、ピクセルは連続的な画像輝度を量子化したサンプルであるグレー値であり、画像配列内の行、列インデックスで指定される画像内位置である。画像配列は矩形格子上の点で画像輝度をサンプリングする事で得られる。x,y座標で指定される画像平面内の点は、ピクセルがサンプルされる格子の間にあるかも知れない。
</p>
<h2>1.7  計算レベル</h2>
<p>
画像は通常いくつかのオブジェクトを含んでいる。ビジョンアプリケーションは通常、画像全体のではなくオブジェクトのある特性を計算する事が必要になる。オブジェクトの特性を計算するためには先ず個々のオブジェクトを別々のオブジェクトとして識別しなければならない。そうすれば個々のオブジェクトに計算を適用する事でオブジェクトの特性を計算する事が出来る。
</p>
<p>
  連結性や異なるオブジェクトを別個のサブ画像として表現する領域分割の定義とアルゴリズムは、2章、3章で紹介する。ここではコンピュータビジョンアルゴリズムを計算の局所性の観点から考えよう。各アルゴリズムを入出力特性の観点から考える。ここでの我々のねらいは、入力と出力の性質や、処理を最適に実現する方法を議論できるように、処理を特徴づける事である。コンピュータビジョンシステムへの入力は画像であるが、出力は画像処理システムとは異なって、オブジェクトの識別や位置等を表す何らかの記号的な量である事に注意して欲しい。ビジョンシステムで処理されるデータの量は非常に多く、これがコンピュータビジョンシステムの計算処理要求を大きなものにしている。ここ数年、コンピュータビジョン用に設計された専用アーキテクチャが多く見られる。演算の特徴を議論して計算処理要求を予測したいので、演算レベルを分類し、それらの一般的な特徴を検討する。
</p>
<h3>1.7.1  点レベル</h3>
<p>
演算によっては画像の1点のみに基づいて出力が生成される。しきい処理はこの例である。しきい処理アルゴリズムは予め設定されたしきいに対する入力値のみに依存して出力を生成する。従って
\[
f_B[i,j]=O_{point}\{f_A[i,j]\} \tag{1.9}
\]
ここで \(f_A\) と \(f_B\) はそれぞれ入力画像、出力画像である。この演算はルックアップテーブルを用いて効率的に実装できる(図1.9参照)。
</p>
<center><img src="images/fig1_9.png"></center>
<p>
図1.9  点操作は個々の画像ピクセルに適用され、その結果として出力画像が出来上がる。しきい処理画像は、グレイレベルを持つ元の画像のピクセルをしきい値より大きい場合は白、それ以外は黒にした画像である。
</p>
<h3>1.7.2  局所レベル</h3>
<p>
局所演算は、入力画像内の対応する点の近傍に依存して点の輝度が決まる出力画像を生成する。従って
\[
f_B[i,j]=O_{local}\{f_A[i_k,j_l]\mid [i_k,j_l]\in N[i,j]\} \tag{1.10}
\]
この様な演算の例を図1.10に示す。平滑化やエッジ検出は局所演算である。これらの演算は入力画像の近傍の値を必要とするので、アレイプロセッサーや単一命令複数データ(SIMD)マシンはこれらの演算の実装に適している。一般にこれらの演算は並列マシンで簡単に実装できリアルタイムで実行できる事が多い。
</p>
<center><img src="images/fig1_10.png"></center>
<p>
図1.10  局所操作は近傍ピクセルに適用され、結果として出力画像を生成する。平滑化画像は元の画像の5×5の局所近傍の平均グレイ値を計算して得られる。
</p>
<h3>1.7.3  大域レベル</h3>
<p>
ある演算の出力は絵全体に依存している。その様な演算は大域演算と呼ばれる。
\[
P=O_{global\{f[i,j]\} \tag{1.11}
\]
この演算[例]を図1.11に示す。
</p>
<center><img src="images/fig1_11.png"></center>
<p>
図1.11  大域操作の例。画像(左)とそのヒストグラム(右)。ヒストグラムは画像内に含まれる各グレイ値のピクセル数をプロットしたものである。
</p>
<p>
  これらの演算の出力は画像であったり記号的な出力だったりする。輝度値のヒストグラムやフーリエ変換は大域演算である。大域演算はビジョンシステムの遅さに対して責任が大きい。高いレベルの演算のほとんどが事実上大域演算であり、アルゴリズムやアーキテクチャ設計の最大の課題となっている事を後で見る。
</p>
<h3>1.7.4  オブジェクトレベル</h3>
<p>
コンピュータビジョンシステムのたいていのアプリケーションは、オブジェクトレベルで計算する特性を必要とする。システムがオブジェクトを認識するためには、オブジェクトのサイズ、平均輝度、形状、その他特性を計算出来なければならない。オブジェクトの他の多くの特性は不足を検出するために決めなければならない。オブジェクトに属すピクセルに制限される演算子は、これらの特性を決めるために適用される事がある。ここから非常に難しい疑問が湧く。オブジェクトとは何か？どうやってオブジェクトを見つけるのか？
</p>
<p>
  オブジェクトは個々の文脈で定義される事を後で見る。実際、マシンビジョンにおける多くの演算は画像内のどこに特定のオブジェクトがあるかを見つけるために実行される。画像内のオブジェクトはcatch-22の状況[JosephHellerの小説。板ばさみ状態のこと]を与えている。オブジェクトのある特性を計算するためにはオブジェクトに属す全ての点を使わなければならないが、それらの点を識別するためにはこの特性を使わなければならない。後で見るように点をオブジェクトにまとめるため、図－地 (figure-ground：背景ピクセルと前景ピクセルを分離する)問題を解こうとする多くの努力が費やされてきた。
  ここでは画像の内容を理解するために、マシンビジョンシステムはオブジェクトレベルで幾つかの演算を実行しなければならない事だけ覚えておこう。
</p>
<h2>1.8  ロードマップ</h2>
<p>
本書はマシンビジョンの実際的なイントロダクションを提供する。各章は簡単な2値世界から、空間的時間的世界のマシンビジョンのアプリケーションを構築する順で紹介する。大雑把に言って、本書の前半は主に2次元、後半は3Dの範囲に広がる。2章－2値画像ではマシンビジョンで使う用語、概念の基礎を紹介する。ここで述べる手法はビジョンシステムの全ての局面で使われる。形態学の手法も紹介する。3章では画像内で領域を見つける手法を紹介する。この章は領域を表現する手法も扱う。全てのビジョンシステムは作業で領域を使わなければならないので、この章で扱う手法はシステムを実装する際の基本になる。4章－フィルタリングでは画像の強調処理を紹介し、フィルタリング手法の基本的な局面について述べる。エッジ検出手法は非常に重要で、多くのマシンビジョンシステムで基本工程となる。5章－エッジ検出では幾つかのエッジ検出手法を紹介し、その様な単純な演算がいかに複雑な処理を伴うかを示す。続く章では輪郭を表現する手法を紹介する。エッジは局所的である。エッジを利用するためにはそれらを意味のあるオブジェクトにまとめ上げて、表現しなければならない。表面検査、場面分類、表面方向・表面形状決定と言ったマシンビジョンの作業ではテクスチャーも重要な役割を果たす。それらの話題は7章で述べる。幾何光学と輻射測定の基本は8章、9章でそれぞれ扱う。色は多くの応用では画像の基本要素であり、10章で述べる。
</p>
<p>
  11章では受動的な方法、能動的な方法を使って画像から奥行き情報を復元する手法を紹介する。ここで述べる手法は我々を2次元画像から3次元へ連れて行く。続く章ではカメラ校正の手法を紹介する。画像から3次元情報を復元するためは、カメラの位置と方向、カメラパラメータを知ることが基本である。カメラを校正する様々な手法がこの章で述べられる。空間中の曲線と局面の表現と特徴が13章で述べられる。補間と近似の手法もこの章で述べる。14章ではダイナミックビジョンについて述べる。画像内の変化を検出する手法や、動きの特徴に基づいて画像を分ける手法、そしてオブジェクトを追跡する手法が紹介される。動きからの構造[復元]がここで簡単に紹介される。オブジェクト認識はビジョンシステムが実行する最も一般的な作業の1つである。オブジェクト認識の基本的な局面を15章で紹介する。
  ここに含まれる題材のほとんどは1学期[半年]で扱う事が出来る。4半期の講義では、幾つかの章を省かなければならないかも知れない。....[以下省略]
</p>
    </body>
</html>