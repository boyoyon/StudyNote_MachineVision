<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>二値画像</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
            .margin-large
            {
                margin-left: 30px;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .two-columns {
            display: flex;
            flex-direction: row;
            gap: 20px; /* 列間のスペース */
        }
        .column {
            flex: 1; /* 各列が均等に幅を取る */
        }
    </style>
<style>
.three-columns {
  display: flex;
  gap: 10px; /* 列間の余白を設定 */
}
.column {
  flex: 1; /* 各列の幅を均等にする */
  padding: 10px; /* 内側の余白を設定 */
}
</style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -30px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 0px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
            ol
            {
                margin-left: 30px;
            }
            ul
            {
                margin-left: 30px;
            }
    </style>
    </head>
    <body>
        <h1><center>2章  二値画像処理</center></h1>
<p>
ディジタル画像を得るために量子化を行うまでは、画像は輝度値の連続体から成っている。画像内の情報はこれらのグレイ値の中にある。画像を解釈するためには、輝度値の変動を解析しなければならない。画像の輝度を表現するために用いられる、最も一般的な量子化レベル数は256階調である。一般的ではないがある種のアプリケーションでは32,64,128,512の輝度レベルに量子化されたディジタル画像も見られる。また医療用では4096(12bit)階調も使われる。当然、輝度レベルが多いほどコストや容量は増えるが表現は良くなる。
</p>
<p>
　マシンビジョンの初期の頃では、利用出来るメモリや処理能力は非常に制限されており、高価だった。これらの制約によりビジョンアプリケーションの設計者がその努力を二値ビジョンシステムに集中させる事が助長された。二値画像は2つのグレイレベルしか含まない。これが場面表現に及ぼす違いを図2.1に示す。
</p>
<center><img src="images/fig2_1.png"></center>
<p>
<center>図2.1  グレイ階調画像とそれに対応する二値画像</center>
</p>
<p>
  更に設計者は、人々が線画やシルエット、2つのグレイ値のみを使って形成された画像を理解する際に困難がない事に注目した。この人間の能力に促されて、彼らは多くのアプリケーションに二値画像を使った。
</p>
<p>
  たとえコンピュータがずっと強力になっても、二値ビジョンシステムは尚役立つ。第一に二値画像の特性を計算するアルゴリズムは十分に理解されている。またそれらはグレーレベルやカラー画像上で動作するビジョンシステムより安価で高速になりやすい。これは二値ビジョンのメモリ要求や処理要求が大幅に小さいためである。256グレーレベルで動作するグレーレベルシステムのメモリ要求は、同じサイズの二値画像で動作するシステムの8倍になる。2.4節で扱うランレングス符号化のような手法を使う事で、格納サイズは更に削減できる。二値画像上の多くの演算は、整数算術演算の代わりに論理演算として実行されるので、処理時間要求も低い。
</p>
<p>
  メモリ要求が小さい事と実行時間が速い事だけが二値ビジョンシステムを研究する理由ではない。これらのシステム用に開発された多くの技術はグレースケール画像を使うビジョンシステムにも適用できるのである。グレーレベル画像やカラー画像の中のオブジェクトを表現する便利な方法はマスクを使う事である。オブジェクトのマスクは二値画像で、オブジェクトの点では1、それ以外では0となる。オブジェクトが背景から分離された後、[色々な]判定をするために幾何学的、位相的な特性が必要とされるかもしれない。この様な特性は二値画像から計算される。本章で述べる手法は全てグレー画像内の領域に適用する事が出来る。従って二値画像の文脈でこれらの手法を述べるが、その応用は二値画像に限られている訳ではない。
</p>
<p>
  一般に、オブジェクトを認識するのに十分な情報をシルエットが持っている場合や、環境を適切に制御できる場合には二値ビジョンシステムは有効である。良好なシルエットを得るためには、オブジェクトは背景から簡単に分離できなければならない。これは特別な照明手法を使い、場面内に数個のオブジェクトしかない場合にのみ可能である。これらの要求を満足できる工業的な状況は数多くある。例えば、二値ビジョンシステムは以下のような用途で応用が見出されている。光学的文字読み取り機(OCR)、染色体解析、工業部品認識、等々。これらの場合、二値ビジョンシステムは通常しきい処理を使ってオブジェクトを背景から分離している。しきい値の適切な値は照明やオブジェクトの反射特性に依存する。結果として生じる二値画像により、与えられた作業に対してオブジェクトの幾何学的、位相的特性(特徴)を計算できる。多くのアプリケーションではこれらの特性はオブジェクトの認識に十分である。
</p>
<p>
  しかし、アプリケーションが複雑になるに従って、段々グレースケール画像を使ったビジョンシステムが多くなる事は言っておくべきであろう。これは多くの材料を扱ったり組み立てたりする作業では、オブジェクトと背景で良好なコントラストを得られるように照明を制御できないためである。照明や、場面内の他のオブジェクトの反射特性の小さな変動にシステムが過敏にならないように注意しなければならない。多くのアプリケーションではこれは難しい作業になる。同様に検査作業では、2つだけの輝度レベルを使って微妙な情報を復元する事は不可能になるかもしれない。オブジェクトの内部の詳細はしきい処理で失われるかもしれず、表面の欠陥を検出する事を難しくするかもしれない。
</p>
<p>
  本章では二値画像に関するある一般的な慣例に従う。それはオブジェクトに含まれるピクセルは値 \(1\) で、背景に含まれるオブジェクトは値 \(0\) になると言うものである。二値画像では背景が白で、オブジェクトは黒になる。また画像サイズは \(n×m\) ピクセルで、コンピュータ内では2次元配列で表現されていると仮定する。この表現により、人々が慣れている形を維持しながら、点と点の空間関係で画像を視覚化する事が出来る。
</p>
<p>
  本章で述べる手法は単純であるが、工業ビジョンで非常に重要な役割を果たしている。本章では二値ビジョンシステムの以下の局面を検討する。
<div class="styleBullet">
<ul>
<li> ・二値画像の形成</li>
 <li>・幾何学的特性</li>
 <li>・位相的特性</li>
 <li>・二値画像内のオブジェクト認識</li>
</ul>
</div>
</p>
<p>
  ここで述べる多くの概念はマシンビジョンのあらゆる局面で使われる。多くの定義はディジタル的な幾何学と関連しておりサンプルされた画像と関連した議論で有効である。一般に、画像は幾つかのオブジェクトに分割された後では、各オブジェクトは領域として表現される。これらのオブジェクト領域と関係した議論は、本章で述べる用語と概念を使う。
</p>
<h2>2.1  しきい処理</h2>
<p>
ビジョンシステムにおける最も重要な問題の1つは、オブジェクトを表している部分画像を識別する事である。この操作は、人間にとってはとても当たり前で簡単な事であるが、コンピュータには驚くほど難しい。画像を領域に分ける事 (partitioning) を領域分割 (segmentation) と呼ぶ。理想的には、分割はオブジェクトかオブジェクトの一部を表現する。形式的には領域分割は、画像 \(F[i,j]\)を領域と呼ばれる、オブジェクトの候補となる部分画像 \(P_1,････,P_k\) に分割する方法として定義される。
<div class="styleBullet">
<ul>
<li><strong>定義2.1</strong>　領域とは画像の部分集合である</li>
<br>
<li><strong>定義2.2</strong>　領域分割とは以下の様に、ピクセルをグループ化して領域にする事である。</li>
<br>
<ul>
<li>・\(\bigcup\limits_{i=1}^k P_i\)＝画像全体  ( つまり\(\{P_i\}\) は隙間の無い分割 )</li><br>
<li>・\(P_i\cap P_j=\emptyset,\; i\neq j\)  ( つまり\(\{P_i\}\) は排他的[＝重複の無い]分割 )</li><br>
<li>・各領域 \(P_i\) は1つの属性を満たす。つまり分割内の全ての点はある共通する特性を持つ</li><br>
<li>・隣接する領域に属するピクセルを一緒に取ると、それらのピクセルはこの属性を満足しない
</ul>
</ul>
</div>
</p>
<p>
  上で見たように、分割はある属性を満たす。この属性は輝度が均一であると言う様に簡単なものかも知れないが、たいていのアプリケーションではもっと複雑である。領域分割は画像理解における非常に重要な工程である。
</p>
<p>
  二値画像はグレースケール画像に適当な領域分割を使って得られる。もしもオブジェクトの輝度がある範囲にあり、背景のピクセルの輝度がその範囲外なら、その輝度範囲内の点を1とし範囲外の点を0とするしきい処理を使って二値画像を得る事が出来る。従って二値ビジョンでは領域分割としきい処理は同義になる。このしきい処理をハードウェアで実行するために多くのカメラが設計されてきた。その様なカメラの出力は二値画像である。しかし、たいていのアプリケーションではカメラはグレースケール画像を与え、二値画像はしきい処理を使って得られる。
</p>
<p>
しきい処理は、注目しているオブジェクトを背景から分離する様にグレースケール画像を二値画像に変換する方法である。しきい処理がオブジェクト－背景分離で効果的になるためには、どれがオブジェクトの輝度で、どれが背景の輝度か判るのに十分なコントラストをオブジェクトと背景が持つ必要がある。固定しきい処理手法では、これらの輝度特性がしきい値を決める。
</p>
<p>
  二値画像 \(B[i, j]\) は、オリジナルのグレー画像 \(F[i,j]\) にしきい値 \(T\)を使って作ったしきい処理後の画像 \(F_T[i,j]\) と同じと仮定しよう。従って
\[
B[i,j]=F_T[i,j] \tag{2.1}
\]
ここで明るい背景に暗いオブジェクトがある場合、
\[
F_T[i,j]=
\begin{cases}
1　if　F[i,j]\leqq T \\
0　othersize 
\end{cases}
\tag{2.2}
\]
オブジェクトの輝度値が \([T_1,T_2]\) の範囲にある事が分かっているなら、以下を使う事も出来る。
\[
F_T[i,j]=
\begin{cases}
1　if　T_1\leqq F[i,j]\leqq T_2 \\
0　otherwise
\end{cases}
\tag{2.3}
\]
オブジェクトの輝度レベルが幾つかの分離した区間から出来ている一般のしきい処理手法では以下の様に表現できる。
\[
F_T[i,j]=
\begin{cases}
1　if　F[i,j]\in Z \\
0　otherwise
\end{cases}
\tag{2.4}
\]
ここで \(Z\) はオブジェクト成分の輝度値の集合である。異なるしきいを使って作られた画像を図2.2に示す。
</p>
<center><img src="images/fig2_2.png"></center>
<p>
<center>図2.2  グレイ・レベル画像と異なるしきい値による二値画像</center>
</p>
<p>
  適用する領域に関する知識がしきい処理アルゴリズムにどう盛り込まれるかに注目して欲しい。実際しきい値は領域毎に調整されている。従って同じしきい値では新しい領域でうまく動作しないであろう。しきいは通常、適用領域に関する経験に基づいて選ばれる。場合によっては、システムの初めの数回の実行は対話的な場面の解析として利用され、しきいに適した値が決められる。
</p>
<p>
  画像の自動しきい処理はマシンビジョンシステムにおける画像解析の第一段階である事が多い。適当なしきい値を自動的に選択するために、画像内の輝度分布や注目しているオブジェクトの知識を利用する手法が数多く開発されてきた。それは図1.11で簡単に紹介されている。そこでは画像とそのヒストグラムが与えられている。この様に画像をしきい処理する自動的な手法の多くは3.2節で紹介する。
</p>
<h2>2.2  幾何学的特性</h2>
<p>
しきい処理手法によって画像内のオブジェクトが与えられていると仮定しよう。次の工程はオブジェクトを認識して位置を突き止める事である。たいていの工業アプリケーションではカメラ位置と環境は分かっている。簡単な幾何学を使えば、画像内の2次元位置からオブジェクトの3次元位置が見つかる。更にたいていのアプリケーションでは、別個のオブジェクトの数はそれほど多くない。オブジェクトのサイズや形が異なるなら、システムによるオブジェクト認識を助けるために画像からオブジェクトのサイズや形状の特徴が決められるかも知れない。工業用の多くのアプリケーションでは、オブジェクトの位置をつきとめたり、オブジェクトを認識したりするために簡単な特徴(例えば形・位置・向き)が使われる。
</p>
<p>
  幾つかのオブジェクトがある場合には、各オブジェクトに対してこれらの特徴を計算する事も出来る。オブジェクトは通常、連結された成分または領域で表現される。連結性の概念や画像の中から連結している成分を見つけるアルゴリズムについては本章の後半で述べる。ここでの議論では画像にはオブジェクトが1つしか無いものと仮定しよう。
</p>
<h3>2.2.1 サイズ</h3>
<p>
一般に二値画像に対しては面積 \(A\) が以下で与えられる事が広く知られている。
\[
A=\sum_{i=1}^n\sum_{j=1}^mB[i,j] \tag{2.5}
\]
これは0次モーメントである。
</p>
<h3>2.2.2 位置</h3>
<p>
画像内のオブジェクトの位置は多くのアプリケーションで重要な役割を演じる。オブジェクトの位置を指定する方法には、外接矩形を使ったり重心を使ったりと幾つかある。工業的応用ではオブジェクトはテーブルの様に通常見える面が分かっており、テーブルに対するカメラ位置も分かっている。この様な場合には、画像内のオブジェクトの位置は空間的な位置で決まる。画像内のオブジェクトの位置はオブジェクト画像の領域中心を使って定義される事もある。オブジェクト画像の外接矩形と言った他の方法が使われる事もあるが、領域中心は点であり、比較的画像ノイズの影響を受けない。
  二値画像の領域中心は、点の輝度をその点の質量と考えるなら質量中心(重心)と同じになる。オブジェクトの位置を計算するために以下の式を使う。
\[
\begin{align}
\bar x\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}B[i,j] &=\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}jB[i,j] \tag{2.6} \\
\\
\bar y\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}B[i,j] &= -\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}iB[i,j] \tag{2.7}
\end{align}
\]
(ここから蛇足)<br>
   <br>
　数学で一般的な (x,y) の順ではなく, 行列の順(行, 列)なので注意。更に...<br>
　\(y\) 軸(実数の縦軸)は上向きが正, \(i\) 軸(整数の縦軸)は下向きが正なのでマイナスがつく<br>
　\(x\) 軸(実数の横軸)は右向きが正, \(j\) 軸(整数の横軸)も右向きが正なのでマイナスはつかない<br>
   <br>
(ここまで蛇足)<br><br>
ここで \(\bar x\) と \(\bar y\) は領域の中心の座標である。従ってオブジェクトの位置は以下のようになる。
\[
\begin{align}
\bar x &=\frac{\sum\limits_{i=0}^{n-1}\sum\limits_{j=0}^{m-1}jB[i,j]}{A} \tag{2.8} \\
\\
\bar y &=\frac{-\sum\limits_{i=0}^{n-1}\sum\limits_{j=0}^{m-1}iB[i,j]}{A} \tag{2.9}
\end{align}
\]
これらは1次モーメントである。1次モーメントを使って計算した位置は必ずしも整数にはならず、通常は画像配列インデックスの整数値の間になる。これは算出した位置がピクセル座標の解像度よりも良い事を意味するものではない事は強調しておく。
</p>
<h3>2.2.3 方向</h3>
<p>
オブジェクトの方向を計算する事は位置を計算するより多少複雑である。(円の様な)ある種の形では方向は一意に決まらない。一意な方向を定義するためにはオブジェクトは細長くなければならない。そうなら伸長部の軸の方向をオブジェクトの方向として定義する事が出来る。一般には、2Dでは最小慣性の軸と等価である最小2次モーメントの軸が伸長部の軸として使われる。
</p>
<p>
  オブジェクト画像に対する2次モーメントの軸は、オブジェクト内の点と直線の距離の2乗和が最小となる直線である。二値画像 \(B[i,j]\)を与えた場合、二値画像内のオブジェクト点に対して最小2乗適合する直線を計算する。[つまり]直線から全てのオブジェクト点までの垂直距離の2乗和を最小にする。
\[
\chi^2=\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}r_{ij}^2B[i,j] \tag{2.10}
\]
ここで \(r_{ij}\) はオブジェクト点 \([i,j]\) から直線までの垂直距離である。直線が垂直に近い場合の数値問題を避けるため、極形式で直線を表現する。
\[
\rho=x\cdot\cos\theta+y\cdot\sin\theta \tag{2.11}
\]
図2.3に示す様に \(θ\) は \(x\) 軸に対する法線の方向で、\(ρ\) は原点から直線までの距離である。点 \((x,y)\) の[直線までの]距離 \(r\) は直線の式に点の座標を入れる事で得られる。
</p>
<center><img src="images/fig2_3.png"></center>
<p>
<center>図2.3　直線の極座標表現</center>
</p>
\[
r^2=(x\cos\theta+y\sin\theta-\rho)^2 \tag{2.12}
\]
<p>
  最小化判定[式(2.10)の事]に直線の表現を代入すると、オブジェクト点に直線を当て嵌めると言う回帰直線問題が出来上がる。
\[
\chi^2=\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}(x_{ij}\cos\theta+y_{ij}\sin\theta-\rho)^2B[i,j] \tag{2.13}
\]
</p>

<p>
\(\rho\) に関する の導関数を \(0\) として \(\rho\) について解くと以下の様になる。
<p>
(ここから蛇足)
</p>
<center><img src="images/fig2_0.png"></center>
<p>
\(\theta\) は一旦定数と仮定して \(\rho\) の極大を探す。
\[
\begin{align}
\frac{\partial \chi^2}{\partial\rho} &= -2\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}(x_{ij}\cos\theta+y_{ij}\sin\theta+\rho)B[i,j]=0 \\
\\
&=-2\left(\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}x_{ij}\cos\theta B[i,j]+\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}y_{ij}\sin\theta B[i,j]-\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}\rho B[i,j]\right)=0 \\
\\
&=-2\left(\cos\theta\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}x_{ij} B[i,j]+\sin\theta\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}y_{ij} B[i,j]-\rho\underbrace{\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}B[i,j]}_{=A}\right)=0 \\
\\
&=-2\left(\cos\theta\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}x_{ij}B[i,j]+\sin\theta\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}y_{ij}B[i,j]-\rho\cdot A\right)=0\\
\end{align}
\]
<br>

\[
\begin{align}
&\cos\theta\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}x_{ij}B[i,j]+\sin\theta\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}y_{ij}B[i,j]-\rho\cdot A = 0 \\
\\
&\cos\theta\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}x_{ij}B[i,j]+\sin\theta\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}y_{ij}B[i,j] =\rho\cdot A \\
\\
&\cos\theta\underbrace{\frac{\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}x_{ij}B[i,j]}{A}}_{=\bar x}+\sin\theta\underbrace{\frac{\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}y_{ij}B[i,j]}{A}}_{=\bar y}=\rho
\end{align}
\]
(ここまで蛇足)
\[
\rho=\bar x\cos\theta+\bar y\sin\theta \tag{2.14}
\]
これは回帰線がオブジェクトの中心 を通る事を示している。上の に関する式にこの \(\rho\) の値を代入して以下の置換を行うと、
\[
x^\prime=x-\bar x　y^\prime=y-\bar y \tag{2.15}
\]
</p>
<p>
(ここから蛇足)
\[
\begin{align}
\chi^2 &=\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}(x_{ij}\cos\theta+y_{ij}\sin\theta-\rho)^2B[i,j] \\
\\
&=\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}\{(x_{ij}^\prime+\bar x)\cos\theta+(y_{ij}^\prime+\bar y)\sin\theta-\rho\}^2B[i,j] \\
\\
&=\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}(x_{ij}^\prime\cos\theta+y_{ij}^\prime\sin\theta+\underbrace{\bar x\cos\theta+\bar y\sin\theta-\rho}_{=0})^2B[i,j]\\
\\
&=\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}({x_{ij}^\prime}^2\cos^2\theta+2x_{ij}^\prime y_{ij}^\prime\cos\theta\sin\theta+{y_{ij}^\prime}^2\sin^2\theta)B[i,j]\\
\\
&=\underbrace{\sum_{i=0}^{n-1}\sum_{j=0}^{m-1} {x_{ij}^\prime}^2B[i,j]}_{=a}\cos^2\theta+  \underbrace{2\sum_{i=0}^{n-1}\sum_{j=0}^{m-1}x_{ij}^\prime y_{ij}^\prime B[i,j]}_{=b}\cos\theta\sin\theta + \underbrace{\sum_{i=0}^{n-1}\sum_{j=0}^{m-1} {y_{ij}^\prime}^2 B[i,j]}_{=c}\sin^2\theta
\end{align}
\]
(ここまで蛇足)
</p>
<p>
最小化問題は次のようになる。
\[
\chi^2 = a\cos^2\theta+b\sin\theta\cos\theta+c\sin^2\theta \tag{2.16}
\]
パラメータ
\[
\begin{align}
a &= \sum_{i=0}^{n-1}\sum_{j=0}^{m-1}(x_{ij}^\prime)^2B[i,j] \tag{2.17}\\
\\
b &= 2\sum_{i=0}^{n-1}\sum_{j=0}^{m-1} x_{ij}^\prime y_{ij}^\prime B[i,j] \tag{2.18}\\
\\
c &= \sum_{i=0}^{n-1}\sum_{j=0}^{m-1} (y_{ij}^\prime)^2 B[i,j] \tag{2.19}
\end{align}
\]
は2次モーメントである。<br>
<br>
(ここから蛇足)<br><br>
\(\cos^2=\frac{1+\cos 2\theta}{2}, \sin^2\theta=\frac{1-\cos 2\theta}{2}, \sin\theta\cos\theta=\frac{sin 2\theta}{2}\) を使うと \(\chi^2\) の式は以下の様に書き換えられる。
\[
\begin{align}
\chi^2 &=a\cos^2\theta+b\cos\theta\sin\theta+c\sin^2\theta \\
\\
&=a\left(\frac{1}{2}+\frac{\cos 2\theta}{2}\right)+b\frac{\sin 2\theta}{2}+c\left(\frac{1}{2}-\frac{\cos 2\theta}{2}\right) 
\end{align}
\]
(ここまで蛇足)<br>
<br>
\(\chi^2\) の式は以下の様に書き換えられる。
\[
\frac{1}{2}(a+c)+\frac{1}{2}(a-c)\cos 2\theta + \frac{1}{2}b\sin 2\theta \tag{2.20}
\]
\(\chi^2\) を \(\theta\) で微分して結果を \(0\) にし、\(θ\) について解くと<br>
<br>
(ここから蛇足)<br>
<br>
\[
\begin{align}
&\frac{\partial \chi^2}{\partial\theta} =\frac{1}{2}\cdot 2\cdot (a-c)\sin 2\theta - \frac{1}{2}\cdot 2\cdot b\cdot\cos 2\theta \\
\\
&(a-c)\sin 2\theta=b\cos 2\theta
\end{align}
\]
(ここまで蛇足)<br>
<br>
\[
\tan 2\theta=\frac{b}{a-c} \tag{2.21}
\]
軸の方向は以下で与えられる。
\[
\begin{align}
\sin 2\theta &=\pm\frac{b}{\sqrt{b^2+(a-c)^2}} \tag{2.22} \\
\\
\cos 2\theta &=\pm\frac{a-c}{\sqrt{b^2+(a-c)^2}} \tag{2.23}
\end{align}
\]
方向の軸[主軸]は \(\chi^2\) の最小値に対して得られる。\(b＝0\) かつ \(a＝c\) ならオブジェクトは一意な主軸を持たない事に注意。オブジェクトの伸長度(elongation) \(E\) は の最大値と最小値の比である。
\[
E=\frac{\chi_{max}}{\chi_{min}} \tag{2.24}
\]
\(\sin 2\theta\) と \(\cos 2\theta\) の式を式(2.20)に代入すると、その符号により が最大か最小か決まる。円では伸長度は \(1\) であり、これが \(E\) の下限である事に注意。
</p>
<h2>2.3  投影</h2>
<p>
二値画像の直線への投影は、直線をビン(bin 置き場)に分割し、各ビンに直交する直線にのっている \(1\) のピクセルを探す事で得られる。簡単な例を図2.4に示す。
</p>
<center><img src="images/fig2_4.png"></center>
<p>
<center>図2.4　とかげの二値画像とその水平投影と垂直投影</center>
</p>
<p>
投影は画像の簡潔な表現である。なぜなら多くの役に立つ情報が投影にそのまま残るからである。しかし2つ以上の画像が同じ投影を持つと言う意味では、投影は一意ではない。水平投影や垂直投影は図2.5に示す様に、それぞれ垂直、水平のビンに入っている1のピクセルの数を求める事で簡単に得られる。
</p>
<center><img src="images/fig2_5.png"></center>
<p>
<center>図2.5  画像の水平投影と垂直投影</center>
</p>
<p>
　二値画像の行に沿った投影 \(H[i]\) と、列に沿った投影 \(V[j]\) は以下で与えられる。
\[
\begin{align}
H[i] &=\sum_{j=0}^{m-1}B[i,j] \tag{2.25} \\
\\
V[j] &=\sum_{i=0}^{n-1}B[i,j] \tag{2.26}
\end{align}
\]
</p>
<p>
任意の直線への一般投影も定義出来る。対角投影の例を図2.6に示す。
</p>
<center><img src="images/fig2_6.png"></center>
<p>
<center>図2.6　二値とかげ画像とその対角投影</center>
</p>
<p>
画像の1次モーメントは、その投影の1次モーメントに等しい事が示される。オブジェクトの位置の計算は1次モーメントしか必要としないので、位置は水平投影と垂直投影から計算できる。つまり、
\[
\begin{align}
A &=\sum_{j=0}^{m-1}V[j]=\sum_{u=0}^{n-1} H[i] \tag{2.27}\\
\\
\bar y &=\frac{\sum\limits_{i=0}^{n-1}iH[i]}{A} \tag{2.28} \\
\\
\bar x &=\frac{\sum\limits_{j=0}^{m-1}jV[j]}{A} \tag{2.29}
\end{align}
\]
</p>
<p>
  前節で見た様に、オブジェクトの方向は2次モーメントの知識を必要とする。2次モーメントは画像の対角投影から計算できる。従って方向は、水平投影、垂直投影、対角投影から計算できる。
</p>
<p>
  アプリケーションによっては、投影がオブジェクト認識の特徴として使われる。投影は簡潔な表現を提供し、高速なアルゴリズムのアプリケーションを可能にする。
</p>
<p>
  対角投影を更新するトリックは、現在の行と列のヒストグラム配列[buket：バケツ]へのインデックスを計算すると言うものである。行と列をそれぞれ \(i,j\) と表すとしよう。画像の寸法を \(n\) 行 \(m\) 列と仮定すると、\(i\) と\(j\) はそれぞれ \(0～n－1\)と \(0～m－1\) の範囲になり、対角に対するインデックス \(d\) は行と列のアフィン変換(一次結合＋定数)として計算できる。
\[
d=ai+bj+c \tag{2.30}
\]
対角投影は \(n＋m－1\) の配列を必要とする。アフィン変換は右上のピクセルを対角投影の最初に写像し、左下のピクセルを最後の位置に写像する。方程式を解くと、
\[
\begin{align}
a\cdot 0+b(m-1)+c &=0  \tag{2.31} \\
\\
a(n-1)+b\cdot 0+c &=n+m-2 \tag{2.32} \\
\\
a &= -b \tag{2.33}
\end{align}
\]
下式が得られる。
\[
d=i-j+m-1 \tag{2.34}
\]
</p>
<h2>2.4 ランレングス符号化</h2>
<p>
二値画像のもう一つの簡潔な表現はランレングス符号化である。この表現では画像内の1のピクセルの連なり(Run)の長さが画像表現として使われる。この符号化は画像転送で使われる。更にオブジェクトの面積と言った特性のあるものがランレングス符号から直接計算できる。
</p>
<p>
  ランレングス符号化では2つの手法が一般に使われる。1番目の手法では、各行の1のランの開始位置と長さが使われる。もう一つの手法は1のランから始めてランの長さのみを使う。我々は2番目の規約を使い、画像の各行のラン長を表現する。従って \(r_{i,k}\) は画像の第 \(i\) 行の \(k\) 番目のランを意味する。ある画像に対するランレングス符号を図2.7に示す。
</p>
<p>
二値画像
</p>
<center><img src="images/fig2_7.png"></center>
<p>
\(1\) の連なりの開始位置と長さ
<div class="styleBullet">
<ul><ul><ul>
<li>(1,3) (7,2) (12,4) (17,2) (20,3)</li>
<li>(5,13) (19,4)</li>
<li>(1,3) (17,6)</li>
</ul></ul></ul>
</div></p>
<p>
\(1\) の連なりの長さと \(0\) の連なりの長さ
<div class="styleBullet">
<ul><ul><ul>
<li>3,3,2,3,4,1,2,1,3</li>
<li>0,4,13,1,4</li>
<li>3,13,6</li>
</ul></ul></ul>
</div>
<center>図2.7  簡単な二値画像に対する[2通りの]ランレングス符号</center>
</p>
<p>
  全てのオブジェクトの面積は1のランの全ての長さを足す事で得られる。
\[
A=\sum_{i=0}^{n-1}\sum_{k=0}^{(\frac{m_i-1}{2})} r_{i,2k+1} \tag{2.35}
\]
ここで \(m_i\) は第 \(i\) 行のランの数である。
</p>
<p>
  水平投影は画像を生成しなくてもランレングス符号から簡単に計算出来る(図2.8参照)。垂直投影と対角投影もうまく考えられた符号を使う事で、画像を生成しなくても計算出来る。画像の他の特性を計算する事は、画像の部分的な、あるいは完全な生成を必要とする。
</p>
<center><img src="images/fig2_8.png"></center>
<p>
<center>図2.8　ランレングス・コードから算出された水平投影</center>
</p>
<h2>2.5  二値アルゴリズム</h2>
<p>
オブジェクトピクセルを背景ピクセルから分離する事は難しい問題である。ここではこの問題に着手しない。ここでは何らかの方法でオブジェクトが定義されており、述語(predicate)を使ってオブジェクトに属する画像の点がラベル付け出来ると仮定しよう。そうすると問題はオブジェクト点としてラベル付けされた画像の全ての点を、オブジェクト画像へとグループ化する事になる。本章ではこの様な点は全て近くにあると仮定する。この空間的近接性(aproximity)の概念は、空間的に近くにあるピクセルを構成成分へとグループ化するアルゴリズムを考案できるほどに正確に定義する必要がある。この為、幾つかの定義を導入する。
</p>
<h3>2.5.1 定義</h3>
<h4>近傍(neighbor)</h4>
<p>
ディジタル画像内のピクセルは他のいくつかのピクセルと空間的に近接している。正方格子で表現されているディジタル画像の場合には、1つのピクセルは4つのピクセルと共通の境界を持ち、更に4つのピクセルと角を共有する。2つのピクセルが共通のピクセルを共有している場合、そのピクセルを4近傍と言う。同様に2つのピクセルが少なくても1つの角を共有する場合、8近傍と言う。例えば、位置 \([i,j]\) にあるピクセルの4近傍は \([i+1,j]、[i－1,j]、[i,j+1]、[i,j－1]\) である。
</p>
<center><img src="images/fig2_02.png"></center>
<p>
8近傍は先の4近傍に加えて \([i+1,j+1]、[i+1,j－1]、[i－1,j+1]、[i－1,j－1]\) が含まれる。4近傍の関係にあるピクセル同士は4連結であると言い、8近傍の関係にあるピクセル同士は8連結と言われる。
</p>
<center><img src="images/fig2_03.png"></center>
<h4>パス(path)</h4>
<p>
\([i_0, j_0]\) のピクセルから \([i_n, j_n]\) のピクセルまでのパス[経路]とは、\(0≦k≦n－1\) の範囲の \(k\) に対して \([i_k, j_k]\) が 
\([i_{k+1}, j_{k+1}]\) の近傍となる様なピクセルの連なり \([i_0, j_0] [i_1, j_1]･･･ [i_n, j_n]\) の事を言う。近傍関係として4連結を使うならパスは4パスである。8連結を使うなら8パスである。それらの簡単な例を図2.10に示す。
</p>
<center><img src="images/fig2_10.png"></center>
<p>
<center>図2.10　4パスと8パスの例</center>
</p>
<h4>フォアグラウンド(Foreground)</h4>
<p>
画像内の1のピクセルの集合をフォアグラウンドと呼び、Sと表記する。
</p>
<h4>連結性(Connectivity)</h4>
<p>
\(S\) に属するピクセルだけを用いて \(p\) から \(q\) までのパスが存在する場合、ピクセル \(p∈S\) はピクセル \(q∈S\) と連結であると言う。
</p>
<p>
  連結性は同値関係である事に注意して欲しい。\(S\) に属す任意の3ピクセル \(p,q,r\) に対して以下の性質が成り立つ。
<div class="styleBullet">
<ul>
<li>1. ピクセル \(p\) は \(p\) と連結である(反射律 reflextivity)</li>
<li>2.  \(p\) が \(q\) と連結なら、\(q\) は \(p\) と連結である(交換律 commutativity 対称律とも言う)</li>
<li>3.  \(p\) が \(q\) と連結で、\(q\) が \(r\) と連結ならば、\(p\) は \(r\) と連結である(推移律 transitivity)</li>
</ul>
</div>
</p>
<h4>連結成分(Connected Component)</h4>
<p>
各ピクセルが他の全てのピクセルと連結しているピクセルの集合を連結成分と呼ぶ。
</p>
<h4>バックグラウンド(Background)</h4>
<p>
画像の境界を含む \(\bar S(S\) の補集合)の連結成分の集合をバックグラウンドと呼ぶ。バックグラウンド以外の \(\bar S\) を穴(hole)と呼ぶ。
</p>
<p>
  以下の簡単な絵を考えよう。
</p>
<center><img src="images/fig2_04.png"></center>
<p>
この図には何個のオブジェクトと何個の穴があるだろう？フォアグラウンド、バックグラウンド共に4連結で考えるなら、1ピクセルサイズのオブジェクトが4個と穴が1個となる。8連結ならオブジェクトが1個で穴が無い。直感的にどちらも曖昧な状況である[1ピクセルサイズのオブジェクトしかないのに穴が出来たり、1つのオブジェクトで囲まれているのに穴が無かったり等]。同様の曖昧さは以下の単純な場合にも起こる。
</p>
<center><img src="images/fig2_05.png"></center>
<p>
\(1\) が連結なら \(0\) は連結になるべきではない。
</p>
<p>
　この具合の悪い状況を避けるためにはオブジェクトと背景で異なる連結性を使うべきである。つまり \(S\) に8連結を使うなら \(\bar S\) には4連結を使うべきである。
</p>
<h4>境界(Boundary)</h4>
<p>
\(S\) の境界とは、\(\bar S\) の4近傍となっている \(S\) のピクセルの集合の事である。境界は通常 \(S^\prime\) と表記される。
</p>
<h4>内部(Interior)</h4>
<p>
内部とは境界ではない \(S\) のピクセルの集合の事である。つまり \(S\) の内部とは\((S－S^\prime)\) である。
</p>
<h4>包囲(Surrounds)</h4>
<p>
領域 \(T\) が領域 \(S\) を囲む(あるいは \(S\) は \(T\) の内部である)とは、\(S\) の任意の点から絵の境界への任意の4パスが \(T\) を横切らなければならない事を言う。図2.11に境界、内部、包囲の簡単な二値画像の例を示す。
</p>
<center><img src="images/fig2_11.png"></center>
<p>
<center>図2.11　二値画像とその境界、内部、周囲</center>
</p>
<h3>2.5.2 成分ラベル付け(Component Labeling)</h3>
<p>
マシンビジョンで最も一般的な操作の一つは、画像内で連結している成分を見付ける事である。連結している成分の点はオブジェクトを表現する領域の候補となる。前に述べた様に、コンピュータビジョンではたいていのオブジェクトは表面を持つ[と仮定している]。表面に属する点は空間的に近い点に投影される。"空間的に近い"と言う考えはディジタル画像では連結した成分として捉えられる。ここで連結成分アルゴリズムが通常は二値ビジョンシステムのボトルネックになっている事は言っておくべきであろう。アルゴリズムは事実上、逐次的(sequencial)である。なぜなら連結成分を見つける操作は大域操作だからである。画像内に1個のオブジェクトしかないなら連結成分を探す必要はない。しかし画像内に多くのオブジェクトがあり、オブジェクトの属性や位置を見付ける必要があるのなら、連結成分を判断しなければならない。
</p>
<p>
マシンビジョンで最も一般的な操作の一つは、画像内で連結している成分を見付ける事である。連結している成分の点はオブジェクトを表現する領域の候補となる。前に述べた様に、コンピュータビジョンではたいていのオブジェクトは表面を持つ[と仮定している]。表面に属する点は空間的に近い点に投影される。"空間的に近い"と言う考えはディジタル画像では連結した成分として捉えられる。ここで連結成分アルゴリズムが通常は二値ビジョンシステムのボトルネックになっている事は言っておくべきであろう。アルゴリズムは事実上、逐次的(sequencial)である。なぜなら連結成分を見つける操作は大域操作だからである。画像内に1個のオブジェクトしかないなら連結成分を探す必要はない。しかし画像内に多くのオブジェクトがあり、オブジェクトの属性や位置を見付ける必要があるのなら、連結成分を判断しなければならない。
</p>
<center><img src="images/fig2_12.png"></center>
<p>
<center>図2.12　画像とその連結成分画像</center>
</p>
<h4>再帰(Recursive)アルゴリズム</h4>
<p>
再帰アルゴリズムはアルゴリズム2.1で与えられる。シーケンシャルプロセッサーでは、このアルゴリズムは極めて非効率である。非効率のため、このアルゴリズムは汎用コンピュータで使われる事は滅多にない。しかし並列マシンでは一般的に使われている。
<div class="styleBullet">
<ul>
<li>1. 画像を走査してラベル付けされていない1のピクセルを探し、新しいラベルLを割り当てる</li>
<li>2. そのピクセルの1の近傍全てに再帰的にラベルLを割り当てる</li>
<li>3. ラベル付けされていない1のピクセルが無くなったなら停止する</li>
<li>4. ステップ1に戻る</li>
</ul>
</div>
<center>アルゴリズム2.1  再帰的連結成分アルゴリズム</center>
</p>
<h4>逐次(Sequencial)アルゴリズム</h4>
<p>
逐次アルゴリズムは通常、画面全体の2パスを必要とする。このアルゴリズムは一時に画像の2行のみを使って動作するので、たとえ画像がファイルに格納されていて空間的制約から画像全体をメモリに持ってくる事が許されなくても使う事が出来る。アルゴリズム2.2で与えられるこのアルゴリズムはピクセルの近傍を見て1のピクセルで既に使われているラベルを割り当てようとする。ピクセルの近傍が異なるラベルの場合には、同値になる全てのラベルを見失わないように同値テーブルで下調べを行う。このテーブルは2回目のパスで成分の全てのピクセルに一意なラベルを割り当てるために使われる。
<div class="styleBullet">
<ul>
<li>1. 画像を左から右、上から下に走査する</li>
<li>2. ピクセルが1ならば</li>
<ul>
<li>(a) 上と左の近傍の一方だけがラベルを持つならばラベルをコピーする</li>
<li>(b) 2つが同じラベルを持つならラベルをコピーする</li>
<li>(c) 両方が異なるラベルを持つなら、上のラベルをコピーして、両方のラベルを同値ラベルとして同値テーブルに入れる</li>
<li>(d) それ以外ならこのピクセルに新しいラベルを割り当て、そのラベルを同値テーブルに入れる</li>
</ul>
<li>3. まだ検討するピクセルが残っているならステップ2に戻る</li>
<li>4. 同値テーブル内の各同値集合に対して最小のラベルを見つける</li>
<li>5. 絵を走査する。各ラベルを同値集合内の最小ラベルで置き換える</li>
</ul>
</div>
<center>アルゴリズム2.2  4連結を使った逐次連結成分アルゴリズム</center>
</p>
<p>
  このアルゴリズムでは画像を左から右、上から下へ走査する際に、検討すべき3つの場合がある。このアルゴリズムはピクセルの4近傍の内の2つしか見ない。上と左である。この2つのピクセルはアルゴリズムによって既に見られている事に注意して欲しい。もしもこれらのピクセルがどちらも \(1\) でないなら、ピクセルには新しいラベルが必要である。どちらか一方のピクセルが \(1\) でラベルLが割り当てられているなら、ピクセルには \(L\) が割り当てられる。両方のピクセルが \(1\) で、同一のラベルLが割り当てられているなら、ピクセルには \(L\) が割り当てられる。しかし近傍が異なるラベル \(M,N\) を割り当てられているなら、同じ成分に2つのラベルが割り当てられている事になり、統合されなければならない。この場合ピクセルはどちらか一方のラベル、通常は小さい値のラベルが割り当てられ、両方のラベルが同値ラベルとして同値テーブルに記録される。
</p>
<p>
  同値テーブルは各連結成分に一意のラベルを割り当てる為の情報を収めている。1回目の走査では、1つの成分に属する全てのラベルが同値であると宣言される。2回目のパスで同値な集合から1つのラベルが選ばれ、成分の全てのピクセルに割り当てられる。一般には成分には最小のラベルが割り当てられる。2回目のパスは各成分に一意のラベルを割り当てる。
</p>
<p>
  連結成分が全て見つかった後で、ラベル番号にとびが出来ない様に、同値テーブルを再番号付けすべきである。それから同値テーブルをルックアップテーブルとして使って、画像内のラベルを再番号付けするために画像を再走査する。
</p>
<p>
各成分の面積、1次モーメント、2次モーメントは逐次連結成分アルゴリズムの一部として計算される。もちろん各領域でモーメントを累算するために、別々の変数を使わなければならない。領域を統合する際には、各領域のモーメントの累算値を単に足し合わせれば良い。
</p>
<h3>2.5.3 サイズフィルター</h3>
<p>
二値画像を得るためにしきい処理を使う事が非常に一般的である。たいていの場合、画像にはノイズによる領域がある。一般にその様な領域は小さい。多くの応用では注目しているオブジェクトはサイズが \(T_0\) ピクセルより大きい事が分かっている。その様な場合には、成分ラベル付けが終わった後で、サイズフィルターを使ってノイズを取り除く事が出来る。サイズが \(T_0\) を下回る成分は全て対応するピクセルを \(0\) にする事で取り除かれる。この単純なフィルター処理メカニズムはノイズ除去に非常に有効である。図2.13と2.14はノイズのある文字画像にサイズフィルターを適用した例を示している。
</p>
<center><img src="images/fig2_13.png"></center>
<p>
<center>図2.13　ノイズのある文字 "\(i\)" の二値画像(左)と \(T=10\) のサイズフィルター適用後の画像(右)</center>
</p>
<center><img src="images/fig2_14.png"></center>
<p>
図2.14　サイズフィルター閾値 \((T=25)\) のお粗末な選択の結果起こり得る誤り。文字 "\(i\)" のドットが無くなっていることに注意
</p>
<h3>2.5.4 オイラー数(Euler Number)</h3>
<p>
多くの応用で、オブジェクトの特徴として種数(genus)またはオイラー数が使われる。Genusは成分の数から穴の数を引いたものとして定義される。つまり
\[
E=C-H \tag{2.36}
\]
</p>
<p>
ここで \(E,C,H\) はそれぞれオイラー数、成分の数、穴の数である。これは平行移動、回転、スケーリングに不変な簡単なトポロジー的な特徴を与える。ランの様な局所的な構造を使ってgenusを計算する事が出来るアルゴリズムが幾つか開発されている。図2.15はオブジェクトと対応するオイラー数の例である。
</p>
<center><img src="images/fig2_15.png"></center>
<p>
図2.15　文字 "\(A\)"、"\(B\)"、"\(i\)"とそれぞれのオイラー数。前景には8連結、背景には4連結が使われていることに注意
</p>
<h3>2.5.5 領域境界(Region Boundary)</h3>
<p>
連結成分 \(S\) の境界は と隣接する \(S\) のピクセルの集合である。境界のピクセルを探すために簡単な局所操作が使われる。たいていの応用では境界上のピクセルを特定の順番に追跡したい。一般的な1つの手法は領域の全ての点を時計周りに追跡する方法である。ここでは簡単な境界追跡(boundary-following)アルゴリズムについて述べる。
</p>
<p>
  境界追跡アルゴリズムは開始点 \(s∈S\) を選び、境界が画像の縁にはないと仮定しながら、開始ピクセルに戻るまで境界を追跡する。このアルゴリズムをアルゴリズム2.3で与える。このアルゴリズムはサイズが \(1\) より大きい全ての領域で動作する。8連結領域に対してこのアルゴリズムで見つかる境界を図2.16に示す。
</p>
<center><img src="images/fig2_16.png"></center>
<p>
図2.16　境界追跡アルゴリズムの結果。左：オリジナル・オブジェクト。右：計算された境界
</p>
<p>
<div class="styleBullet">
<ul>
<li>1. 画像の左から右、上から下と言った組織的な走査を使って、領域に対する開始点 \(s\in S\) を見つける</li>
<li>2. 境界追跡中の現在のピクセルを \(c\) と表記する事にしよう。\(c=s\) と設定し、\(s\) の西側[左側]の4近傍は \(b\in\bar S\)とする</li>
<li>3. \(c\) の8近傍を \(b\) から始めて時計周りに \(n_1,n_2･･･n_8\) とする。\(S\) に属する最初の \(n_i\) を探す</li>
<li>4. \(c=n_i, b=n_i－1\) に設定する</li>
<li>5. \(c=s\) となるまでステップ3,4を繰り返す</li>
</ul>
</div>
<center>アルゴリズム2.3  境界追跡アルゴリズム</center>
</p>
<h3>2.5.6  面積(Area)と周囲長(Perimeter)</h3>
<p>
前に述べた様に、面積は \(S\) の中のピクセルの数である。幾つかの成分 \(S_1,S_2･･･S_n\) がある場合、各成分の面積はその成分の中のピクセルの数になる。各成分の中のピクセル数は成分のラベル付けと一緒に得られる。一般の場合、n成分の各面積は画像の1回の走査で得られる。
</p>
<p>
  成分の周囲長は多くの異なる方法で定義できる。幾つかの一般的な定義には以下がある。<br>
<br>
<div class="styleBullet">
<ul>
<li>1. \(\bar S\) のピクセルから \(S\) のピクセルを隔てている"ひび(cracks)"の長さの和。ひびとは \(p∈S, q∈\bar S\) となるピクセル対 \(p,q\)を隔てる直線の事である。</li>
<br>
<li>2. 境界追跡アルゴリズムで要するステップ数</li>
<br>
<li>3. \(S\) の境界ピクセルの数</li>
</ul>
</div>
</p><p>
測定される周囲長は、定義の違いに従って大きく異なる。一般に、定義1を使って得られる周囲長は他の2つを使って測った周囲長よりも長くなる。
</p>
<h3>2.5.7 コンパクト性(Compactness)</h3>
<p>
連続的な幾何学図形のコンパクト性は等周不等式(isoperimetric inequality)で計られる事が広く知られている。
\[
\frac{P^2}{A}\geq4\pi \tag{2.37}
\]
ここで \(P, A\) はそれぞれ図形の周囲長、面積である。円はこの計量に関しては最もコンパクトな図形である(つまりコンパクト性の最小値を持つ)。円の場合、\(P^2/A\) の比は最小値4πに達する。他の図形ではこの比率はもっと大きい。観察者に対してある角度をなしている円を考えよう。円を傾斜させるに従って形が長円になると仮定すると、面積は減少するものの円周長はそれほど急激には減らないのでコンパクト性が増す。傾斜の最大角で長円は直線に押し込められ、コンパクト性は無限大になる。ディジタル画像では \(P^2/A\) は外接矩形の長さをサイズ(ピクセル数)で割る事により計算する。これは分散性(?dispersedness)やコンパクト性の良い計量となる。この比率は領域の特徴として多くの応用で使われている。
</p>
<p>
  コンパクト性の別の見方は、コンパクトな領域ほど与えられた周囲長で広い面積を囲むと言うものである。同じ周囲長では正方形の方が長方形よりコンパクトである事に注目して欲しい。
</p>
<h3>2.5.8 距離計量</h3>
<p>
多くの応用で、画像内の2つのピクセル間や2つの成分間の距離を求める事が必要になる。あいにくディジタル画像で距離を定義する唯一の方法はない。距離は多くの異なる方法で定義できる。任意のピクセル \(p,q,r\) に対して、どんな距離も以下の3つの性質を満たさなければならない。<br>
<div class="styleBullet">
<ul>
<li>1. \(d(p,q)≧0\) ここで \(d(p,q)＝0 ⇔ p＝q\)</li>
<br>
<li>2. \(d(p,q)＝d(q,p)\)</li>
<br>
<li>3. \(d(p,r)≦d(p,q)+d(q,r)\)</li>
</ul>
</div>
</p>
<p>
ディジタル幾何学では、幾つかの異なる距離関数が使われている。一般的な距離関数のいくつかを以下に示す。
ユークリッド距離
\[
d_{Eucidean}([i_1,j_1],[i_2,j_2])=\sqrt{(i_1-i_2)^2+(j_1-j_2)^2} \tag{2.38}
\]
<br>
マンハッタン距離(City-block)
\[
d_{city}=|i_1-i_2|+|j_1-j_2| \tag{2.39}
\]
チェスボード距離(Chess board)
\[	　
d_{chess}=max(|i_1-i_2|,|j_1-j_2|) \tag{2.40}
\]
マンハッタン距離とチェスボード距離は計算が簡単なので、ユークリッド距離よりも好まれる。これら3つの関数を図2.17で図説している。
</p>
<center><img src="images/fig2_17.png"></center>
<p>
<center.図2.17　(a)ユークリッド距離、(b)街区画距離、(c)チェス盤距離の例</center>
</p>
<p>
  ある距離計量に従った距離 \(≦k\) のピクセルの集合は、その計量における半径kの円盤(disc)と呼ばれる。図2.18は上の3つの計量でのサイズ3の円盤を示している。距離計量を使う際に重要な項目は、ユークリッド距離は連続の場合に最も近い距離を与えるものの、コンピュータ処理的には高価で結果が実数になると言う事実である。整数化するためにユークリッド距離の2乗も距離計量として使われる。
</p>
<p>
ユークリッド距離:
</p>
<center><img src="images/fig2_18_1.png"></center>
<p>
マンハッタン距離:
</p>
<center><img src="images/fig2_18_2.png"></center>
<p>
チェスボード距離:
</p>
<center><img src="images/fig2_18_3.png"></center>
<p>
<center>図2.18  異なる距離計量</center>
</p>
<h3>2.5.9 距離変換</h3>
<p>
文字認識の様なある種のアプリケーションでは、オブジェクト成分のピクセルとバックグラウンド間の最小距離が使われる。従ってオブジェクト \(S\) が与えられると、\(S\) の全てのピクセルに対して、バックグラウンド領域 までの距離を計算しなければならない。この様な距離を表現する画像を得るための変換を距離変換と呼ぶ。距離変換を計算する並列反復アルゴリズムは以下の式を使って得られる。
\[
\begin{align}
f^0[i,j] &=f[i,j] \tag{2.41} \\
\\
f^m[i,j] &= f^0[i,j]+\min(f^{m-1}[u,v]) \tag{2.42}
\end{align}
\]
ここで \(m\) は \(d([u,v],[i,j])＝1\) となる全てのピクセル \([u,v]\) に対する反復回数である。これは \([i,j]\) の4近傍のみを使う事に注意。
</p>
<p>
  このアルゴリズムは のピクセルは変更しない。1回の繰り返しで と隣接していないピクセルは2に変わる。続く繰り返しでは から離れているピクセルが変化する。全てのピクセルに対して距離が割られた後ではピクセルはもはや変化しない。このアルゴリズムの動作を図2.19に示す。
</p>
<center><img src="images/fig2_19.png"></center>
<p>
<center>図2.19  繰り返し1回目、2回目が終わった後の画像の距離変換</center>
</p>
<h3>2.5.10 中心軸(Medial Axis)</h3>
<p>
\([i,j]\) の全ての近傍 \([u,v]\) で以下を満たす場合、\(S\) 内のピクセル \([i,j]\) から \(\bar S\) への距離 \(d([i,j],\bar S)\) は極大であると言う。
\[
d([i,j],\bar S) \geq d([u,v],\bar S) \tag{2.43}
\]
 \(\bar S\) への距離が極大となる \(S\) のピクセルの集合は、\(S\) の骨格(skeleton)、対称軸(symmetric axis)、中心軸(medial axis)と呼ばれ、\(S^*\) と表記される。中間軸変換の例の幾つかを図2.20で与える。図2.21は元の画像のわずかなノイズにより結果の中間軸変換に重大な差が生じる事を示している。
</p>
<center><img src="images/fig2_20.png"></center>
<p>
<center>図2.20　中心軸変換(medial axis transform)の例</center>
</p>
<center><img src="images/fig2_21.png"></center>
<p>
図2.21　ノイズのある画像に対する中心軸変換の結果。結果は図2.20の最初の例と大きく異なることに注目
</p>
<p>
  元の集合 \(S\) は、\(S^*\) 及び \(S^*\) の各ピクセル からの距離により再構成する事が出来る。[従って]\(S^*\) は \(S\) の簡潔な表現である。\(S^*\) は領域の形状を表現するために使われる。\(\bar S\) からの距離が小さい \(S^*\) のピクセルを除去する事により \(S^*\) の簡易版を作る事が出来る。
</p>
<p>
  中間軸はオブジェクトの簡潔な表現として使われてきた。しかし二値画像の領域は境界を使って表す事も出来る。境界を表す一連のピクセルを得るために境界追跡アルゴリズムが使われる。後の節で見る様に境界はチェーンコードを使って非常に簡潔に表現できる。任意のオブジェクトに対して境界は領域のより簡潔な表現である。しかし与えられたピクセルが領域に属すか否かを求めるためには、中心軸表現が適している。それは中間軸で表現された領域の内部のピクセルは、距離変換で与えられる様に軸上のピクセルと各ピクセルの極大円盤[maximal disc]を使って簡単に検出できると言う事実による。
</p>
<h3>2.5.11 細線化(Thinning)</h3>
<p>
細線化とは、二値化した画像の領域を、骨格(skeletons)、核線(?core lines)とも呼ばれる領域の中心線を近似した線へと縮小する画像処理操作の事を言う。細線化の目的は、後の解析や認識を容易にするために画像成分を基本的情報へと縮小する事である。細線化操作は任意の形状の領域を含む二値画像に適用できるが、凸やbloblike(?しみ状)形状とは反対に主に細長い形状に使われる。細線化は、線画における直線表現や、テキスト画像における文字ストローク用の文書解析アプリケーションの前処理として一般的に使われている。
</p>
<p>
　細線化の要件は形式的には以下の様に記述できる。
<div class="styleBullet">
<ul>
<li>1. 連結した画像成分は、連結した線構造へと細められなければならない</li>
<li>2. 細くした結果は、少なくても8連結になるべきである(後で説明する)</li>
<li>3. 近似端点の位置は保存すべきである</li>
<li>4. 細くした結果は中間線の近似になるべきである</li>
<li>5. 細線化で生じる無関係な出っ張り(短い枝)は最小限にすべきである</li>
</ul>
</div>
</p>
<p>
要件1で規定した様に、細線化の結果が連結性を保持しなければならないと言う事が基本である。これにより連結線構造の数が元の画像の連結領域の数と等しい事が保証される。要件2は、結果として生じる線が常に8連結を保持する最小限のピクセルを含む事を規定している。要件3は端点の位置を保持すべきであると述べている。細線化は外側の境界ピクセルを繰り返し除去するので、線の端点は繰り返し除去しない事は重要である。端点を繰り返し除去すると線を短くし、位置を保存できない。要件4は結果として生じる線が元の領域の中間線を最も良く近似すべきである事を述べている。あいにくディジタル空間では真の中間線は近似するしかない。例えば2ピクセル幅の垂直線や水平線では、真の中間線は元の線の中線に沿って半ピクセル離れた所を走る。ディジタル画像でこれを表現する事は出来ないので、結果は元の線の一方の側を走る事になる。要件5に関しては、ノイズを最小化すべき事は明らかではない[？ある]が、どれがノイズであり、どれがノイズでないかを言うのは困難である事が多い。元の領域の小さな起伏に起因する刺は要らないが、幾分大きな起伏が特徴である場合には認識したい。細線化アルゴリズムによっては刺を除去するパラメータを持つものもあるが、我々は細線化とノイズ除去は別々に実行されるべきであると考えている。ある人が欲しない刺が別の人の欲する短い直線かも知れないので、先ず細線化を行いその後で別の処理として指定した最短の長さより短い刺を除去する事が最善である。
</p>
<p>
  一般の細線化手法は最小でも3×3の近傍領域内の画像内の各ピクセルを調べて、領域が細線に縮小されるまで1回に1ピクセル厚の領域境界をむく。この処理は繰り返し実行される。各繰り返しで全ての画像ピクセルはn×nウィンドウ内で検査され、連結性の維持で必要とされなかったり直線の端点でなかったりする単一ピクセル厚の境界は消去される。図2.22で、\(1\) の領域の外側の層がむかれて行く様子を見る事が出来る。繰り返しで変化が起こらなくなると、処理は完了し画像は細線化された事になる。
</p>
<center><img src="images/fig2_22.png"></center>
<p>
図2.22　文字 "\(e\)" の細線化の5回の繰り返しシーケンス。各繰り返しで境界層が1枚ずつ剥がされていく。繰り返し5でピクセルが変化しなくなり終わりが検出される
</p>
<h3>2.5.12 拡大(Expanding)と縮小(Shrinking)</h3>
<p>
画像成分は組織的に膨らませたり縮ませたりする事が出来る。成分がある背景ピクセルを1に変えるような変更が許される場合、この処理は拡大(expanding)と呼ばれる。オブジェクトピクセルが組織的に削除されたり0に変えられたりする場合、縮小(shrinking)と呼ばれる。拡大と縮小の簡単な実装は次のようになる。<br>
<br>
<strong>拡大:</strong>　近傍のピクセルのどれかが \(1\) なら、そのピクセルを \(0\) から \(1\) に変える。<br>
<strong>縮小:</strong>　近傍のピクセルのどれかが \(0\) なら、そのピクセルを \(1\) から \(0\) に変える。<br>
<br>
従って縮小は背景の拡大と考える事が出来る。これらの処理の例を図2.23で与える。拡大や縮小のような単純な処理が非常に役立つ事に使われ、外見上は画像への複雑な処理に見える事は興味深い。
</p>
<center><img src="images/fig2_23.png"></center>
<p>
図2.23　文字 "\(S\)" への拡大と縮小操作の例。左：オリジナル画像、中央：拡大画像、右：縮小画像
</p>
<p>
以下の様に表記する事にしよう。<br>
\[
\begin{align}
S^{(k)} &: Sをk回拡大したもの\\
S^{(-k)} &: Sをk回縮小したもの
\end{align}
\]
</p>
<p>
　以下の性質が満たされる事が示される。
\[
\begin{align}
(S^m)^{-n} &\neq(S^{-n})^m \\
& \neq S^{m-n} \\
\\
S &\subset (S^k)^{-k} \\
S &\supset (S^{-k})^k
\end{align}
\]
</p>
<p>
　拡大の後の縮小は不要な穴を塞ぐために使う事が出来、縮小の後の拡大は孤立したノイズを削除するために使う事が出来る(図2.24参照)。拡大と縮小は孤立している成分や集団を決めるために使う事が出来る。形態学的画像処理や膨張処理、浸食処理では、拡大と縮小の一般化された形式が多くの作業を行うために広く使われている。
</p>
<center><img src="images/fig2_24.png"></center>
<p>
図2.24　文字 "\(h\)" の拡大と縮小のシーケンス。上段：オリジナルのノイズを含んだ画像。中段：拡大とその後の縮小。下段：縮退の後の膨張。拡大後の縮小は効果的に穴を埋めるがノイズは除去しない。反対に縮小後の拡大はノイズを除去するが穴は埋めないことに注意。
</p>
<h2>2.6 形態学的演算子(Morphological Operator)</h2>
<p>
数学的形態学はその名を形状の研究から取っている。この手法は多くのマシンビジョン応用ではアルゴリズムを設計する場合、形の観点から考える事が自然で楽であると言う事実を利用している。形態学的手法は形状ベースの、または図象的な思考を容易にする。形態学的手法における絵の情報の基本単位は二値画像である。
</p>
<p>
　2つの二値画像 \(A,B\) の交わり(intersction)は \(A∩B\) と記し、\(A\) と \(B\) の両方が \(1\) であるピクセル \(p\) で \(1\) となる二値画像である。従って
\[
A\cap B=\{p\mid p\in A\;かつ\;p\in B\} \tag{2.44}
\]
</p>
<p>
　\(A\) と \(B\) の和集合(union)は \(A∪B\) と記し、\(A\) または \(B\) (または両方)で \(1\) となるピクセル  \(p\) で \(1\) となる二値画像である。記号的には
\[
A\cup B=\{p\mid \in A\;または\;p\in B\} \tag{2.45}
\]
\(\Omega\) を普遍二値画像(全て \(1\))とし、\(A\) をある二値画像としよう。\(A\) の補集合(complement)は \(A\) の \(1\) を \(0\) に入れ替えた二値画像である。従って
\[
\overline{A}=\{p\mid p\in\Omega\;かつ\;p\notin A\} \tag{2.46}
\]
</p>
<p>
　インデックスが \([i,j],[k,l]\) である2つのピクセル \(p\) と \(q\) のベクトル和はインデックスが \([i+k,j+l]\) のピクセル \(p+q\) である。ベクトル差分 \(p－q\) はインデックスが \([i－k,j－l]\) のピクセルである。
</p>
<p>
　 \(A\) が二値画像で \(p\) がピクセルであるとすると、\(p\) によるAの平行移動とは以下で与えられる画像の事である。
\[
A_p=\{a+p\mid a\in P\} \tag{2.47}
\]
</p>
<h4>膨張(Dilation)</h4>
<p>
ピクセル \(p\) による二値画像 \(A\) の平行移動は \(A\) の原点を \(p\) に移す。 \(A_{b_1}、A_{b_2}、･･･A_{b_n}\) が二値画像 \(B＝\{b_1,b_2,･･･b_n\}\) の \(1\) のピクセルによる二値画像Aの平行移動であるとすると、\(B\) の \(1\) のピクセルによるAの平行移動の和集合は \(B\) による \(A\) の膨張(dilation)と呼ばれ、以下で与えられる。
\[
A\oplus B=\bigcup\limits_{b_i\in B} A_{b_i}=\bigcup\limits_{a_i\in A} B_{a_i} \tag{2.48}
\]
(ここから蛇足)<br>
　・分かりにくいが、元絵(A)をペン先が太いペン(B)でなぞるような感じ。あえてはみ出させる。<br>
　・衝突判定などに出てくる「ミンコフスキー和」と同じような気がする。<br>
(ここまで蛇足)
</p>
<p>
　 膨張は結合可能(associative)で交換可能(commutative)の両方の性質を持つ。従って膨張工程の並びでは操作の実行順序は重要ではない。この事実により複雑な形状を一連の膨張で再構成できる幾つかの単純な形状へ分解することが出来る。
</p>
<h4>浸食(Erosion)</h4>
<p>
膨張の反対が浸食である。二値画像 \(B\) による二値画像 \(A\) の浸食とは、ピクセル \(p\) に \(B\) を平行移動した場合、\(B\) の全ての \(1\) のピクセルが \(A\) でも \(1\) になるようなピクセル \(p\) の事である。浸食は以下で与えられる。
\[
A\ominus B=\{p\mid B_p\subseteq A\} \tag{2.49}
\]
(ここから蛇足)<br>
　・分かりにくいが、元絵(A)の背景を先が太い消しゴム(B)でなぞるような感じ。<br>
(ここまで蛇足)
</p>
<p>
二値画像  \(B\) は画像 \(A\) へのプローブとして使われる規則的な形状の場合が多く、構成要素と呼ばれる。浸食は多くの応用で非常に重要な役割を果たす。構成要素による画像の浸食は、構成要素が画像に含まれるような点を与える画像を生じる。
</p>
<p>
　図2.25から図2.28は、単純な二値オブジェクトと上辺を下にしたT字型構成要素を使った膨張と浸食を図説している。図2.26は構成要素を元の図の1のピクセルへの平行移動の例を示す。そこでは構成要素全体は、元のオブジェクト内に完全には収まっていない。この場合、膨張では構成要素の全ての点が最終膨張画像に存在し、元のオブジェクトには含まれていなかったピクセルも含まれる。しかし浸食操作の場合には、構成要素全体がオブジェクト内には収まっていないので構成要素の原点のピクセルは取り除かれる。それに比べて構成要素全体が元のオブジェクトに完全に収まる場合には、最終膨張画像も最終浸食画像も変化しない(ピクセルは加えられもしないし削除もされない)。
</p>
<center><img src="images/fig2_25.png"></center>
<p>
図2.25　オリジナル・テスト画像 \(A\)(左)と構造化要素 \(B\)(右)。構造化要素の原点は \(B\) のその他のピクセルよりも暗く記されていることに注意
</p>
<center><img src="images/fig2_26.png"></center>
<p>
図2.26　構造化要素 \(B\) 全体が \(A\) に収まらないところでは \(A\) 内で構造化要素 \(B\) を1ピクセルだけ平行移動する。膨張処理では構造化要素のすべてのピクセルが最終画像に存在する。侵食処理では構造化要素の原点にあるピクセルは削除される。
</p>
<center><img src="images/fig2_27.png"></center>
<p>
\[
A\oplus B=\bigcup\limits_{b_i\in B} A_{b_i}
\]
<center>図2.27  \(B\) による \(A\) の膨張。元の図 \(A\) の境界を太線で示している。</center>
</p>
<center><img src="images/fig2_28.png"></center>
<p>
\[
A\ominus B=\{p\mid B_p\subseteq A\}
\]
<center>図2.28  \(B\) による \(A\) の浸食。元の図 \(A\) の境界を太線で示している</center>
</p>
<p>
　膨張と浸食は論理的と言うより幾何学的双対性を示し、論理的補集合の他に幾何学的補集合を伴う。二値画像の幾何学的補集合は反射(?reflection)と呼ばれる。二値画像 \(B\) の反射は原点に対して \(B\) と対称な二値画像 \(B'\) の事である。つまり
\[
B^\prime = \{-p\mid p\in B\} \tag{2.50}
\]
膨張と浸食の幾何学的双対性は以下の関係で表現できる。
\[
\overline{A\oplus B}=\overline{A}\ominus B^\prime \tag{2.51}
\]
および
\[
\overline{A\ominus B}=\overline{A}\oplus B^\prime \tag{2.52}
\]
幾何学的双対性は、ドモルガンの法則とも呼ばれる論理的双対性とよい対称を成す。
\[
\overline{A\cup B}=\overline{A}\cap\overline{B} \tag{2.53}
\]
および
\[
\overline{A\cap B}=\overline{A}\cup\overline{B} \tag{2.54}
\]
</p>
<p>
膨張と浸食の双対性を図2.29から図2.31で図説している。
</p>
<center><img src="images/fig2_29.png"></center>
<p>
図2.29　Aの相補とBの鏡像。鏡像の構造化要素の原点が暗いピクセルであることに注意
</p>
<center><img src="images/fig2_30.png"></center>
<p>
\[
\overline{A}\ominus B^\prime
\]
図2.30  膨張の双対。Bの鏡像を使ったAの背景の浸食の結果。元の境界をオレンジ色の線で示す。
</p>
<center><img src="images/fig2_31.png"></center>
<p>
\[
\overline{A}\oplus B^\prime
\]
図2.31  浸食の双対。Bの鏡像を使ったAの背景の膨張の結果。元の境界をオレンジ色の線で示す。
</p>
<p>
  浸食と膨張は画像のフィルター処理で使われることが多い。ノイズの性質が判っているならば適した構成要素が使われ、一連の浸食、膨張操作がノイズを除去するために適用される。この様なフィルターは画像内のオブジェクトの形に影響する。
</p>
<p>
  数学的形態学の基本操作は複雑なシーケンスに組み合わせることが出来る。例えば同じ構成要素(プローブ)を使った浸食の後の膨張は、プローブを収めるには小さすぎる領域内の全てのピクセルを除去し、それ以外はそのままにするであろう。このシーケンスをオープニングと呼ぶ。例として円盤形のプローブ画像を使うとすると、円盤より小さい凸部や孤立領域は全て除去される。これはプラスの(?positive)空間的細部を抑圧するフィルターを形成する。残ったピクセルは構成要素がフォアグラウンド内で収まる所を示している。この結果と元の画像の差分はプローブには小さすぎる領域を示しており、アプリケーションによってはこれらは注目すべき特徴になるかも知れない。
</p>
<p>
  逆のシーケンスつまり膨張の後の浸食は、プローブよりも小さい穴や窪みを埋める。これはクロージング)と呼ばれる。これらの操作は同じT字型構成要素を使って図2.32、図2.33で図説されている。ここでも残っているものと同じくらい削除されたものも重要である。この様なフィルターは空間的特徴を抑圧したり、サイズに基づいてオブジェクトを識別したりするために使う事が出来る。使われる構成要素は小型であったり規則的であったりしなければならない訳ではなく、任意の形状で良い。この様にして分布するピクセルから作られる特徴が検出される。
</p>
<center><img src="images/fig2_32.png"></center>
<p>
図2.32　オープニング。左：初期侵食、右：続いて起こる膨張。元の図Aの境界を太線で示す
</p>
<center><img src="images/fig2_33.png"></center>
<p>
図2.33　クロージング。左：初期膨張。右：続いて行われる侵食。元の図Aの境界を太線で示す
</p>
<h2>2.7 光学的文字認識(Optical Character Recognition)</h2>
<p>
文字に比較的ノイズが無く、フォントやサイズが同じ場合には、形態学的操作は光学的文字認識に使うことが出来る。始めに出現する文字が映っている画像から認識すべき文字を抽出する。次に、穴や窪みを埋めるために膨張やクロージングを使う。それから文字画像を縮退して不要な領域を除去し、難なく文字のインスタンス(実例instance)に当てはまるように文字のサイズを減らす。処理されたこの画像は文字のモデルになる。
</p>
<p>
  別の画像で文字インスタンスを認識するため、文字モデルをプローブとして使い、浸食を実行する。浸食を行う前に画像はきれいにしておかなければならないかも知れない(穴は塞ぎ、不要な混乱は除去する)。浸食の後、連結成分を計算し、サイズフィルターを実行して小さすぎる領域を捨て、サイズフィルーをパスした各領域の位置を計算する。これは画像内の文字モデルの認識されたインスタンスの位置を与える。清掃、充填、縮退の後で得られた良質な文字モデルは、フォントやサイズがわずかに異なるインスタンスを含む多くの文字インスタンスと適合する。それでも任意フォント(omnifont)認識は研究者にとって非常に挑戦的な問題である。光学的文字認識は専用ハードウェアを使って実時間で実行されている。
</p>
    </body>
</html>